{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bfBtotJANg9I"
      },
      "outputs": [],
      "source": [
        "paragraph = \"Today was an enchanting day in the countryside, üå≥ where the gentle breeze whispered secrets through the fields üåæ and the golden sun cast a warm glow upon the landscape ‚òÄÔ∏è.\\n The rolling hills stretched for miles, adorned with patches of colorful wildflowers üåº, creating a breathtaking panorama. As I roamed through the meadows, I was serenaded by the melodious chirping of crickets ü¶ó and the soft rustle of leaves in the wind.\\n The earthy scent of freshly cut grass filled the air, mingling with the sweet fragrance of blooming flowers. With each breath, I felt a profound sense of peace wash over me, a reminder of the beauty and tranquility that nature offers.\\n In this idyllic setting, time seemed to stand still, allowing me to fully appreciate the simple joys of life. It's moments like these that remind us to slow down and savor the beauty that surrounds us, even in the midst of life's chaos.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZX-_CBuWiY8"
      },
      "source": [
        "### a. Word Tokenization\n",
        "##### NLTK's word_tokenize function breaks the paragraph into a list of words based on spaces and punctuation, important step in text analysis. Used for sentiment analysis and pre-POS tagging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xmkcT5AWnV6",
        "outputId": "905f9faf-8fc0-4b96-eed1-e6689094e201"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\noelm\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Today', 'was', 'an', 'enchanting', 'day', 'in', 'the', 'countryside', ',', 'üå≥', 'where', 'the', 'gentle', 'breeze', 'whispered', 'secrets', 'through', 'the', 'fields', 'üåæ', 'and', 'the', 'golden', 'sun', 'cast', 'a', 'warm', 'glow', 'upon', 'the', 'landscape', '‚òÄÔ∏è', '.', 'The', 'rolling', 'hills', 'stretched', 'for', 'miles', ',', 'adorned', 'with', 'patches', 'of', 'colorful', 'wildflowers', 'üåº', ',', 'creating', 'a', 'breathtaking', 'panorama', '.', 'As', 'I', 'roamed', 'through', 'the', 'meadows', ',', 'I', 'was', 'serenaded', 'by', 'the', 'melodious', 'chirping', 'of', 'crickets', 'ü¶ó', 'and', 'the', 'soft', 'rustle', 'of', 'leaves', 'in', 'the', 'wind', '.', 'The', 'earthy', 'scent', 'of', 'freshly', 'cut', 'grass', 'filled', 'the', 'air', ',', 'mingling', 'with', 'the', 'sweet', 'fragrance', 'of', 'blooming', 'flowers', '.', 'With', 'each', 'breath', ',', 'I', 'felt', 'a', 'profound', 'sense', 'of', 'peace', 'wash', 'over', 'me', ',', 'a', 'reminder', 'of', 'the', 'beauty', 'and', 'tranquility', 'that', 'nature', 'offers', '.', 'In', 'this', 'idyllic', 'setting', ',', 'time', 'seemed', 'to', 'stand', 'still', ',', 'allowing', 'me', 'to', 'fully', 'appreciate', 'the', 'simple', 'joys', 'of', 'life', '.', 'It', \"'s\", 'moments', 'like', 'these', 'that', 'remind', 'us', 'to', 'slow', 'down', 'and', 'savor', 'the', 'beauty', 'that', 'surrounds', 'us', ',', 'even', 'in', 'the', 'midst', 'of', 'life', \"'s\", 'chaos', '.']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk_tokens = nltk.word_tokenize(paragraph)\n",
        "print(nltk_tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16sLZAM5YPkb"
      },
      "source": [
        "### b. Sentance Tokenization\n",
        "##### NLTK's sent_tokenize function divides the paragraph into a list of sentences, helps in machine translation, sentiment analysis and helps understand context of a sentance.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmz56fomWqGw",
        "outputId": "d961f0e9-3317-4311-b114-98e183708c0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Today was an enchanting day in the countryside, üå≥ where the gentle breeze whispered secrets through the fields üåæ and the golden sun cast a warm glow upon the landscape ‚òÄÔ∏è.', 'The rolling hills stretched for miles, adorned with patches of colorful wildflowers üåº, creating a breathtaking panorama.', 'As I roamed through the meadows, I was serenaded by the melodious chirping of crickets ü¶ó and the soft rustle of leaves in the wind.', 'The earthy scent of freshly cut grass filled the air, mingling with the sweet fragrance of blooming flowers.', 'With each breath, I felt a profound sense of peace wash over me, a reminder of the beauty and tranquility that nature offers.', 'In this idyllic setting, time seemed to stand still, allowing me to fully appreciate the simple joys of life.', \"It's moments like these that remind us to slow down and savor the beauty that surrounds us, even in the midst of life's chaos.\"]\n"
          ]
        }
      ],
      "source": [
        "sent_tokens = nltk.sent_tokenize(paragraph)\n",
        "print(sent_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZIav0i5Y7zQ"
      },
      "source": [
        "### c. Punctuation-based Tokenizer\n",
        "##### This regular expression captures either words or punctuation marks, effectively tokenizing the paragraph, isolate words and phrases delimited by punctuation. Useful in text cleaning, where you want to separate punctuation from words, or for tasks focusing on specific patterns around punctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8fO_ijnYW_3",
        "outputId": "fc33946e-8313-44b1-fb2c-f3b9904254c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Today', 'was', 'an', 'enchanting', 'day', 'in', 'the', 'countryside', ',', 'where', 'the', 'gentle', 'breeze', 'whispered', 'secrets', 'through', 'the', 'fields', 'and', 'the', 'golden', 'sun', 'cast', 'a', 'warm', 'glow', 'upon', 'the', 'landscape', '.', 'The', 'rolling', 'hills', 'stretched', 'for', 'miles', ',', 'adorned', 'with', 'patches', 'of', 'colorful', 'wildflowers', ',', 'creating', 'a', 'breathtaking', 'panorama', '.', 'As', 'I', 'roamed', 'through', 'the', 'meadows', ',', 'I', 'was', 'serenaded', 'by', 'the', 'melodious', 'chirping', 'of', 'crickets', 'and', 'the', 'soft', 'rustle', 'of', 'leaves', 'in', 'the', 'wind', '.', 'The', 'earthy', 'scent', 'of', 'freshly', 'cut', 'grass', 'filled', 'the', 'air', ',', 'mingling', 'with', 'the', 'sweet', 'fragrance', 'of', 'blooming', 'flowers', '.', 'With', 'each', 'breath', ',', 'I', 'felt', 'a', 'profound', 'sense', 'of', 'peace', 'wash', 'over', 'me', ',', 'a', 'reminder', 'of', 'the', 'beauty', 'and', 'tranquility', 'that', 'nature', 'offers', '.', 'In', 'this', 'idyllic', 'setting', ',', 'time', 'seemed', 'to', 'stand', 'still', ',', 'allowing', 'me', 'to', 'fully', 'appreciate', 'the', 'simple', 'joys', 'of', 'life', '.', 'It', 's', 'moments', 'like', 'these', 'that', 'remind', 'us', 'to', 'slow', 'down', 'and', 'savor', 'the', 'beauty', 'that', 'surrounds', 'us', ',', 'even', 'in', 'the', 'midst', 'of', 'life', 's', 'chaos', '.']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "punct_tokens = re.findall(r'\\b\\w+\\b|[.,;!?]', paragraph)\n",
        "print(punct_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lirkG5mrZGeC"
      },
      "source": [
        "### d. Treebank Word Tokenizer\n",
        "##### NLTK's TreebankWordTokenizer uses the Penn Treebank conventions to tokenize words(hyphenated words).  Suitable for tasks where handling contractions and hyphenated words is important, such as in linguistic analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oXrPNFJZCoT",
        "outputId": "91a3753d-c558-4228-b72c-1a9ee6d8da7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Today', 'was', 'an', 'enchanting', 'day', 'in', 'the', 'countryside', ',', 'üå≥', 'where', 'the', 'gentle', 'breeze', 'whispered', 'secrets', 'through', 'the', 'fields', 'üåæ', 'and', 'the', 'golden', 'sun', 'cast', 'a', 'warm', 'glow', 'upon', 'the', 'landscape', '‚òÄÔ∏è.', 'The', 'rolling', 'hills', 'stretched', 'for', 'miles', ',', 'adorned', 'with', 'patches', 'of', 'colorful', 'wildflowers', 'üåº', ',', 'creating', 'a', 'breathtaking', 'panorama.', 'As', 'I', 'roamed', 'through', 'the', 'meadows', ',', 'I', 'was', 'serenaded', 'by', 'the', 'melodious', 'chirping', 'of', 'crickets', 'ü¶ó', 'and', 'the', 'soft', 'rustle', 'of', 'leaves', 'in', 'the', 'wind.', 'The', 'earthy', 'scent', 'of', 'freshly', 'cut', 'grass', 'filled', 'the', 'air', ',', 'mingling', 'with', 'the', 'sweet', 'fragrance', 'of', 'blooming', 'flowers.', 'With', 'each', 'breath', ',', 'I', 'felt', 'a', 'profound', 'sense', 'of', 'peace', 'wash', 'over', 'me', ',', 'a', 'reminder', 'of', 'the', 'beauty', 'and', 'tranquility', 'that', 'nature', 'offers.', 'In', 'this', 'idyllic', 'setting', ',', 'time', 'seemed', 'to', 'stand', 'still', ',', 'allowing', 'me', 'to', 'fully', 'appreciate', 'the', 'simple', 'joys', 'of', 'life.', 'It', \"'s\", 'moments', 'like', 'these', 'that', 'remind', 'us', 'to', 'slow', 'down', 'and', 'savor', 'the', 'beauty', 'that', 'surrounds', 'us', ',', 'even', 'in', 'the', 'midst', 'of', 'life', \"'s\", 'chaos', '.']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "treebank_tokenizer = TreebankWordTokenizer()\n",
        "treebank_tokens = treebank_tokenizer.tokenize(paragraph)\n",
        "print(treebank_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjQExtHUZVLe"
      },
      "source": [
        "### e. Tweet Tokenizer\n",
        "##### NLTK's TweetTokenizer is designed to handle tweets, preserving hashtags and mentions. Ideal for sentiment analysis, topic modeling, and other NLP tasks involving Twitter data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EDoboD_ZPvo",
        "outputId": "de1e9d29-b7b5-454c-c4af-37b7f9a505ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Today', 'was', 'an', 'enchanting', 'day', 'in', 'the', 'countryside', ',', 'üå≥', 'where', 'the', 'gentle', 'breeze', 'whispered', 'secrets', 'through', 'the', 'fields', 'üåæ', 'and', 'the', 'golden', 'sun', 'cast', 'a', 'warm', 'glow', 'upon', 'the', 'landscape', '‚òÄ', 'Ô∏è', '.', 'The', 'rolling', 'hills', 'stretched', 'for', 'miles', ',', 'adorned', 'with', 'patches', 'of', 'colorful', 'wildflowers', 'üåº', ',', 'creating', 'a', 'breathtaking', 'panorama', '.', 'As', 'I', 'roamed', 'through', 'the', 'meadows', ',', 'I', 'was', 'serenaded', 'by', 'the', 'melodious', 'chirping', 'of', 'crickets', 'ü¶ó', 'and', 'the', 'soft', 'rustle', 'of', 'leaves', 'in', 'the', 'wind', '.', 'The', 'earthy', 'scent', 'of', 'freshly', 'cut', 'grass', 'filled', 'the', 'air', ',', 'mingling', 'with', 'the', 'sweet', 'fragrance', 'of', 'blooming', 'flowers', '.', 'With', 'each', 'breath', ',', 'I', 'felt', 'a', 'profound', 'sense', 'of', 'peace', 'wash', 'over', 'me', ',', 'a', 'reminder', 'of', 'the', 'beauty', 'and', 'tranquility', 'that', 'nature', 'offers', '.', 'In', 'this', 'idyllic', 'setting', ',', 'time', 'seemed', 'to', 'stand', 'still', ',', 'allowing', 'me', 'to', 'fully', 'appreciate', 'the', 'simple', 'joys', 'of', 'life', '.', \"It's\", 'moments', 'like', 'these', 'that', 'remind', 'us', 'to', 'slow', 'down', 'and', 'savor', 'the', 'beauty', 'that', 'surrounds', 'us', ',', 'even', 'in', 'the', 'midst', 'of', \"life's\", 'chaos', '.']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "tweet_tokenizer = TweetTokenizer()\n",
        "tweet_tokens = tweet_tokenizer.tokenize(paragraph)\n",
        "print(tweet_tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tEUIZyvZnnX"
      },
      "source": [
        "### f. Multi-Word Expression Tokenizer\n",
        "##### NLTK's MWETokenizer allows tokenization of specific multi-word expressions. Useful in tasks where understanding multi-word phrases is essential, like in specialized domain language processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ul1EkIf2Zk-L",
        "outputId": "2f4dd199-8107-479d-aaa6-e492a28e09b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Today', 'was', 'an', 'enchanting', 'day', 'in', 'the', 'countryside', ',', 'üå≥', 'where', 'the', 'gentle', 'breeze', 'whispered', 'secrets', 'through', 'the', 'fields', 'üåæ', 'and', 'the', 'golden', 'sun', 'cast', 'a', 'warm', 'glow', 'upon', 'the', 'landscape', '‚òÄÔ∏è', '.', 'The', 'rolling', 'hills', 'stretched', 'for', 'miles', ',', 'adorned', 'with', 'patches', 'of', 'colorful', 'wildflowers', 'üåº', ',', 'creating', 'a', 'breathtaking', 'panorama', '.', 'As', 'I', 'roamed', 'through', 'the', 'meadows', ',', 'I', 'was', 'serenaded', 'by', 'the', 'melodious', 'chirping', 'of', 'crickets', 'ü¶ó', 'and', 'the', 'soft', 'rustle', 'of', 'leaves', 'in', 'the', 'wind', '.', 'The', 'earthy', 'scent', 'of', 'freshly', 'cut', 'grass', 'filled', 'the', 'air', ',', 'mingling', 'with', 'the', 'sweet', 'fragrance', 'of', 'blooming', 'flowers', '.', 'With', 'each', 'breath', ',', 'I', 'felt', 'a', 'profound', 'sense', 'of', 'peace', 'wash', 'over', 'me', ',', 'a', 'reminder', 'of', 'the', 'beauty', 'and', 'tranquility', 'that', 'nature', 'offers', '.', 'In', 'this', 'idyllic', 'setting', ',', 'time', 'seemed', 'to', 'stand', 'still', ',', 'allowing', 'me', 'to', 'fully', 'appreciate', 'the', 'simple', 'joys', 'of', 'life', '.', 'It', \"'s\", 'moments', 'like', 'these', 'that', 'remind', 'us', 'to', 'slow', 'down', 'and', 'savor', 'the', 'beauty', 'that', 'surrounds', 'us', ',', 'even', 'in', 'the', 'midst', 'of', 'life', \"'s\", 'chaos', '.']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import MWETokenizer\n",
        "mwetokenizer = MWETokenizer([('rhythmic', 'symphony'), ('water\\'s', 'edge')])\n",
        "mwe_tokens = mwetokenizer.tokenize(nltk.word_tokenize(paragraph))\n",
        "print(mwe_tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP9mr5OGZzgm"
      },
      "source": [
        "###g. TextBlob Word Tokenize\n",
        "##### TextBlob's words attribute provides a convenient way to access the words in the paragraph.  Suitable for quick and simple NLP tasks, especially in educational or prototyping contexts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umXFfNVHZpyc",
        "outputId": "80f1367f-a1f7-4fc7-c004-d6bfdabccfeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Today', 'was', 'an', 'enchanting', 'day', 'in', 'the', 'countryside', 'üå≥', 'where', 'the', 'gentle', 'breeze', 'whispered', 'secrets', 'through', 'the', 'fields', 'üåæ', 'and', 'the', 'golden', 'sun', 'cast', 'a', 'warm', 'glow', 'upon', 'the', 'landscape', '‚òÄÔ∏è', 'The', 'rolling', 'hills', 'stretched', 'for', 'miles', 'adorned', 'with', 'patches', 'of', 'colorful', 'wildflowers', 'üåº', 'creating', 'a', 'breathtaking', 'panorama', 'As', 'I', 'roamed', 'through', 'the', 'meadows', 'I', 'was', 'serenaded', 'by', 'the', 'melodious', 'chirping', 'of', 'crickets', 'ü¶ó', 'and', 'the', 'soft', 'rustle', 'of', 'leaves', 'in', 'the', 'wind', 'The', 'earthy', 'scent', 'of', 'freshly', 'cut', 'grass', 'filled', 'the', 'air', 'mingling', 'with', 'the', 'sweet', 'fragrance', 'of', 'blooming', 'flowers', 'With', 'each', 'breath', 'I', 'felt', 'a', 'profound', 'sense', 'of', 'peace', 'wash', 'over', 'me', 'a', 'reminder', 'of', 'the', 'beauty', 'and', 'tranquility', 'that', 'nature', 'offers', 'In', 'this', 'idyllic', 'setting', 'time', 'seemed', 'to', 'stand', 'still', 'allowing', 'me', 'to', 'fully', 'appreciate', 'the', 'simple', 'joys', 'of', 'life', 'It', \"'s\", 'moments', 'like', 'these', 'that', 'remind', 'us', 'to', 'slow', 'down', 'and', 'savor', 'the', 'beauty', 'that', 'surrounds', 'us', 'even', 'in', 'the', 'midst', 'of', 'life', \"'s\", 'chaos']\n"
          ]
        }
      ],
      "source": [
        "from textblob import TextBlob\n",
        "blob = TextBlob(paragraph)\n",
        "textblob_tokens = blob.words\n",
        "print(textblob_tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyAa8VfbZ6f5"
      },
      "source": [
        "### h. spaCy Tokenizer\n",
        "#####  spaCy tokenizes the paragraph using a sophisticated language model and provides detailed information about each token. Valuable in various NLP tasks, including named entity recognition, dependency parsing, and other advanced applications.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKWyOUe9Z2_v",
        "outputId": "231bb375-d3e7-49c0-8801-fe2a062cd7c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Today', 'was', 'an', 'enchanting', 'day', 'in', 'the', 'countryside', ',', 'üå≥', 'where', 'the', 'gentle', 'breeze', 'whispered', 'secrets', 'through', 'the', 'fields', 'üåæ', 'and', 'the', 'golden', 'sun', 'cast', 'a', 'warm', 'glow', 'upon', 'the', 'landscape', '‚òÄ', 'Ô∏è.', '\\n ', 'The', 'rolling', 'hills', 'stretched', 'for', 'miles', ',', 'adorned', 'with', 'patches', 'of', 'colorful', 'wildflowers', 'üåº', ',', 'creating', 'a', 'breathtaking', 'panorama', '.', 'As', 'I', 'roamed', 'through', 'the', 'meadows', ',', 'I', 'was', 'serenaded', 'by', 'the', 'melodious', 'chirping', 'of', 'crickets', 'ü¶ó', 'and', 'the', 'soft', 'rustle', 'of', 'leaves', 'in', 'the', 'wind', '.', '\\n ', 'The', 'earthy', 'scent', 'of', 'freshly', 'cut', 'grass', 'filled', 'the', 'air', ',', 'mingling', 'with', 'the', 'sweet', 'fragrance', 'of', 'blooming', 'flowers', '.', 'With', 'each', 'breath', ',', 'I', 'felt', 'a', 'profound', 'sense', 'of', 'peace', 'wash', 'over', 'me', ',', 'a', 'reminder', 'of', 'the', 'beauty', 'and', 'tranquility', 'that', 'nature', 'offers', '.', '\\n ', 'In', 'this', 'idyllic', 'setting', ',', 'time', 'seemed', 'to', 'stand', 'still', ',', 'allowing', 'me', 'to', 'fully', 'appreciate', 'the', 'simple', 'joys', 'of', 'life', '.', 'It', \"'s\", 'moments', 'like', 'these', 'that', 'remind', 'us', 'to', 'slow', 'down', 'and', 'savor', 'the', 'beauty', 'that', 'surrounds', 'us', ',', 'even', 'in', 'the', 'midst', 'of', 'life', \"'s\", 'chaos', '.']\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(paragraph)\n",
        "spacy_tokens = [token.text for token in doc]\n",
        "print(spacy_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-dkaNdjad86"
      },
      "source": [
        "### i. Gensim Word Tokenizer\n",
        "##### Gensim's tokenizer is part of the Gensim library, known for topic modeling and document similarity analysis. Used in topic modeling, document clustering, and other tasks related to semantic analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RM5rwpdabcL",
        "outputId": "dfd57e8e-c651-4b48-b076-056fd8a33587"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'gensim'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tokenize\n\u001b[0;32m      2\u001b[0m gensim_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(tokenize(paragraph))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(gensim_tokens)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
          ]
        }
      ],
      "source": [
        "from gensim.utils import tokenize\n",
        "gensim_tokens = list(tokenize(paragraph))\n",
        "print(gensim_tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwAZfnwhcBxu"
      },
      "source": [
        "### j. Tokenization with Keras\n",
        "##### Keras' text_to_word_sequence method tokenizes the paragraph into words while converting everything to lowercase. Used in text classification, language modeling, and sequence-to-sequence tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQtIoUeMcAaS",
        "outputId": "66326197-9974-4d4f-f78b-4a25fdc2f6dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['today', 'was', 'a', 'phenomenal', 'day', 'at', 'the', 'beach', 'üèñÔ∏è', 'filled', 'with', 'the', 'rhythmic', 'symphony', 'of', 'crashing', 'waves', 'üåä', 'and', 'the', 'gentle', 'caress', 'of', 'the', \"sun's\", 'warm', 'embrace', '‚òÄÔ∏è', 'the', 'sandy', 'shore', 'stretched', 'for', 'miles', 'and', 'seagulls', 'soared', 'above', 'creating', 'a', 'picturesque', 'scene', 'as', 'i', 'strolled', 'along', 'the', \"water's\", 'edge', 'i', \"couldn't\", 'help', 'but', 'marvel', 'at', 'the', 'vibrant', 'hues', 'of', 'the', 'sunset', '‚òÄÔ∏è', 'üåÖ', 'painting', 'the', 'sky', 'with', 'breathtaking', 'colors', 'the', 'salty', 'breeze', 'carried', 'away', 'the', 'worries', 'of', 'the', 'day', 'creating', 'a', 'sense', 'of', 'tranquility', 'that', 'i', \"don't\", 'often', 'experience', 'the', 'sand', 'between', 'my', 'toes', 'was', 'a', 'reminder', 'to', 'appreciate', \"life's\", 'simple', 'pleasures', 'i', \"don't\", 'think', \"i've\", 'ever', 'felt', 'more', 'at', 'peace', 'than', 'i', 'did', 'in', 'that', 'moment', \"it's\", 'moments', 'like', 'these', 'that', 'make', 'you', 'realize', 'the', 'importance', 'of', 'taking', 'a', 'break', 'and', 'connecting', 'with', 'nature', \"don't\", 'let', 'the', 'hustle', 'and', 'bustle', 'of', 'daily', 'life', 'prevent', 'you', 'from', 'enjoying', 'the', 'beauty', 'that', 'surrounds', 'us']\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "keras_tokens = text_to_word_sequence(paragraph)\n",
        "print(keras_tokens)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
